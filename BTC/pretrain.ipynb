{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "from scipy.sparse import issparse\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from merge_Dataset import PretrainDataset\n",
    "from main_tcr_train import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# --------------------------- Parse config --------------------------- #\n",
    "argparser = argparse.ArgumentParser()\n",
    "argparser.add_argument('--config', type=str, default='./config.yaml')\n",
    "args = argparser.parse_args()\n",
    "\n",
    "config = load_config(args.config)\n",
    "\n",
    "# Set random seed\n",
    "set_random_seed(config['Train']['Trainer_parameter']['random_seed'])\n",
    "# device = config['Train']['Model_Parameter']['device']\n",
    "device = torch.device(\"cuda:1\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --------------------------- Load and preprocess data --------------------------- #\n",
    "adata = sc.read_h5ad(\"../Data/pretrain_raw_data/merged_8datasets_after_combat_hvg_celltypist.h5ad\")\n",
    "# merged_8datasets_after_combat_hvg_celltypist.h5ad # merged_8datasets_celltype_subset.h5ad\n",
    "if issparse(adata.X):\n",
    "    adata.X = np.array(adata.X.toarray(), dtype=np.float32)\n",
    "else:\n",
    "    adata.X = np.array(adata.X, dtype=np.float32)\n",
    "dataset = PretrainDataset(adata)\n",
    "smile_seqs, vocab_dict = dataset.get_smile_seqs()\n",
    "\n",
    "# print(dataset.type.value_counts())\n",
    "print(\"dataset over\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --------------------------- Initialize and optionally load pretrained model --------------------------- #\n",
    "model = init_model(config, device)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    model.optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=10\n",
    ")\n",
    "# === DataLoader ===\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config['Train']['Sampling']['batch_size'],\n",
    "    shuffle=config['Train']['Sampling']['sample_shuffle']\n",
    ")\n",
    "# === Logger === #\n",
    "output_dir = config['Train']['output_dir']\n",
    "logger = get_logger(f\"{config['Train']['output_dir']}/training_8_datasets_AE.log\")\n",
    "# === Training Params ===\n",
    "epochs = config['Train']['Trainer_parameter']['epoch']\n",
    "patience = config['Train']['Trainer_parameter']['patience']\n",
    "best_loss = float('inf')\n",
    "\n",
    "# === Metrics Storage ===\n",
    "all_loss = []\n",
    "number_of_GEO = len(Counter(dataset.GEOlabel))\n",
    "number_of_beta = len(Counter(dataset.cdr3))\n",
    "number_of_type = len(Counter(dataset.type))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "   total_contrastive, total_recon, total_fusion, epoch_loss = 0,0,0,0\n",
    "   start_time = time.time()\n",
    "\n",
    "   avg_loss, avg_components, all_embeddings, all_rna_embeddings, all_tcr_embeddings, all_GEO_labels, all_beta_labels, all_type_labels = train_one_epoch(model, dataloader, device)\n",
    "   all_loss.append(avg_loss)\n",
    "   logger.info(\n",
    "       f\"Epoch [{epoch}/{epochs}] | Loss : {avg_loss:.5f} | \"\n",
    "       f\"Contrastive: {avg_components['contrastive']:.5f} | \"\n",
    "       f\"Recon: {avg_components['recon']:.5f} | \"\n",
    "       f\"Fusion: {avg_components['fusion']:.5f} | \"\n",
    "       f\"Time: {time.time() - start_time:.2f}s\"\n",
    "   )\n",
    "\n",
    "   ######## Calculzate metrics every 5 epochs ###########\n",
    "   if epoch > 9 and epoch % 5 == 0:\n",
    "       emb = np.vstack(all_embeddings)\n",
    "       enc = LabelEncoder()\n",
    "       nmi_geo = normalized_mutual_info_score(enc.fit_transform(all_GEO_labels), KMeans(n_clusters=number_of_GEO).fit(emb).labels_)\n",
    "       nmi_beta = normalized_mutual_info_score(enc.fit_transform(all_beta_labels), KMeans(n_clusters=number_of_beta).fit(emb).labels_)\n",
    "       nmi_cell = normalized_mutual_info_score(enc.fit_transform(all_type_labels), KMeans(n_clusters=number_of_type).fit(emb).labels_)\n",
    "\n",
    "       print(f\"\\n[Epoch {epoch}] NMI Scores:\")\n",
    "       print(f\"  GEO      NMI: {nmi_geo:.4f}\")\n",
    "       print(f\"  beta   NMI: {nmi_beta:.4f}\")\n",
    "       print(f\"  type NMI: {nmi_cell:.4f}\")\n",
    "   ######## save best model ###########\n",
    "   if avg_loss < best_loss:\n",
    "       best_loss = avg_loss\n",
    "       early_stop_counter = 0\n",
    "       best_epoch_model = model.state_dict()\n",
    "       save_best_model(model, epoch, output_dir, stage=\"pretrain_after_batchremove\")\n",
    "   else:\n",
    "       early_stop_counter += 1\n",
    "\n",
    "   if early_stop_counter >= patience:\n",
    "       logger.info(f\"Early stopping at epoch {epoch}. No improvement for {patience} epochs.\")\n",
    "       break\n",
    "\n",
    "print(\"train over\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 聚类可视化\n",
    "final_embeddings_np = np.vstack(all_embeddings)\n",
    "final_GEO_cluster_labels = np.array(all_GEO_labels)\n",
    "final_beta_cluster_labels = np.array(all_beta_labels)\n",
    "final_type_cluster_labels = np.array(all_type_labels)\n",
    "# save\n",
    "import pickle\n",
    "with open(\"embedding_and_labels.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"embeddings\": final_embeddings_np,\n",
    "        \"GEO_labels\": final_GEO_cluster_labels,\n",
    "        \"beta_labels\": final_beta_cluster_labels,\n",
    "        \"type_labels\": final_type_cluster_labels,\n",
    "        \"all_rna_embeddings\": all_rna_embeddings,\n",
    "        \"all_tcr_embeddings\": all_tcr_embeddings,\n",
    "    }, f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "from matplotlib.lines import Line2D\n",
    "# 使用 UMAP 降维\n",
    "reducer_all = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=100,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine',\n",
    "    n_jobs=-1\n",
    ")\n",
    "reduced_embeddings_umap = reducer_all.fit_transform(final_embeddings_np)\n",
    "print(\"umap all embedding\")\n",
    "\n",
    "# rna\n",
    "final_rna_embeddings_np = np.vstack(all_rna_embeddings)\n",
    "reducer_rna = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=100,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine',\n",
    "    n_jobs=-1\n",
    ")\n",
    "rna_reduced_embeddings_umap = reducer_rna.fit_transform(final_rna_embeddings_np)\n",
    "print(\"rna_embeddings_umap over\")\n",
    "# tcr\n",
    "final_tcr_embeddings_np = np.vstack(all_tcr_embeddings)\n",
    "reducer_tcr = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=100,\n",
    "    min_dist=0.1,\n",
    "    metric='cosine',\n",
    "    n_jobs=-1\n",
    ")\n",
    "tcr_reduced_embeddings_umap = reducer_tcr.fit_transform(final_tcr_embeddings_np)\n",
    "print(\"tcr_embeddings_umap over\")\n",
    "\n",
    "\n",
    "\n",
    "draw_reduced_embeddings_umap = reduced_embeddings_umap\n",
    "visiual_label = final_type_cluster_labels # visiual_label = np.array(adata.obs['cdr3'])\n",
    "\n",
    "unique_labels = np.unique(visiual_label)\n",
    "label_counts = Counter(visiual_label)\n",
    "top_labels = [label for label, _ in label_counts.most_common(5)]\n",
    "top_colors = [plt.cm.tab10(i) for i in range(len(top_labels))]\n",
    "label2color = {label: top_colors[i] for i, label in enumerate(top_labels)}\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in unique_labels:\n",
    "    mask = visiual_label == label\n",
    "    color = label2color.get(label, 'lightgray')  # 非top类默认灰色\n",
    "    plt.scatter(\n",
    "        draw_reduced_embeddings_umap[mask, 0],\n",
    "        draw_reduced_embeddings_umap[mask, 1],\n",
    "        color=color,\n",
    "        s=0.1,\n",
    "        label=str(label) if label in top_labels else None  # 避免重复图例\n",
    "    )\n",
    "legend_handles = [\n",
    "    Line2D([0], [0], marker='o', color='w',\n",
    "           markerfacecolor=label2color[label],\n",
    "           label=label, markersize=4)\n",
    "    for label in top_labels\n",
    "]\n",
    "plt.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"Dataset Labels\",\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(1.02, 0.5),\n",
    "    markerscale=1,\n",
    "    fontsize=10,\n",
    "    title_fontsize=12,\n",
    "    borderaxespad=0,\n",
    "    frameon=False\n",
    ")\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# plt.title(f'UMAP Visualization of top 5 beta {nmi_cell}', fontsize=14)\n",
    "plt.xlabel('UMAP_1', fontsize=12)\n",
    "plt.ylabel('UMAP_2', fontsize=12)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(\"umap_final_beta_cluster_labels.png\", dpi=300, bbox_inches='tight')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
